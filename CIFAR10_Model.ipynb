{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJV4SjlXJC1LfgLN89cZck",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raki-rankawat/pytorch-mobilenet/blob/main/CIFAR10_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "t0ezTciC4oFR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Data Loaders\n",
        "# -----------------------------\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxJgZ9UN4sCN",
        "outputId": "ef3eed39-192b-474d-a40e-14bc40547ea9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:12<00:00, 13.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# MobileNetV2 Blocks\n",
        "# -----------------------------\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride, expand_ratio):\n",
        "        super().__init__()\n",
        "        hidden_dim = int(in_channels * expand_ratio)\n",
        "        self.use_res_connect = stride == 1 and in_channels == out_channels\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        # Expansion\n",
        "        if expand_ratio != 1:\n",
        "            layers.append(nn.Conv2d(in_channels, hidden_dim, 1, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(hidden_dim))\n",
        "            layers.append(nn.ReLU6(inplace=True))\n",
        "\n",
        "        # Depthwise\n",
        "        layers.append(nn.Conv2d(\n",
        "            hidden_dim, hidden_dim, 3,\n",
        "            stride=stride, padding=1,\n",
        "            groups=hidden_dim, bias=False\n",
        "        ))\n",
        "        layers.append(nn.BatchNorm2d(hidden_dim))\n",
        "        layers.append(nn.ReLU6(inplace=True))\n",
        "\n",
        "        # Projection\n",
        "        layers.append(nn.Conv2d(hidden_dim, out_channels, 1, bias=False))\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)"
      ],
      "metadata": {
        "id": "11ar5F_W4wQ6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# MobileNetV2 Model (CIFAR)\n",
        "# -----------------------------\n",
        "\n",
        "class CIFARMobileNetV2(nn.Module):\n",
        "    def __init__(self, num_classes=10, width_mult=1.0):\n",
        "        super().__init__()\n",
        "\n",
        "        input_channel = int(32 * width_mult)\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, input_channel, 3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(input_channel),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "\n",
        "        # t, c, n, s\n",
        "        cfg = [\n",
        "            (1, 16, 1, 1),\n",
        "            (6, 24, 2, 1),\n",
        "            (6, 32, 3, 2),\n",
        "            (6, 64, 4, 2),\n",
        "            (6, 96, 3, 1),\n",
        "            (6, 160, 3, 2),\n",
        "            (6, 320, 1, 1),\n",
        "        ]\n",
        "\n",
        "        layers = []\n",
        "        in_channels = input_channel\n",
        "\n",
        "        for t, c, n, s in cfg:\n",
        "            out_channels = int(c * width_mult)\n",
        "            for i in range(n):\n",
        "                stride = s if i == 0 else 1\n",
        "                layers.append(\n",
        "                    InvertedResidual(in_channels, out_channels, stride, t)\n",
        "                )\n",
        "                in_channels = out_channels\n",
        "\n",
        "        self.blocks = nn.Sequential(*layers)\n",
        "\n",
        "        last_channel = int(1280 * width_mult)\n",
        "\n",
        "        self.conv_last = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, last_channel, 1, bias=False),\n",
        "            nn.BatchNorm2d(last_channel),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(last_channel, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.conv_last(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "QLHDwBUS41ng"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Setup\n",
        "# -----------------------------\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(41)\n",
        "\n",
        "model = CIFARMobileNetV2(width_mult=1.0).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "ey9lVYZA459z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Training Function\n",
        "# -----------------------------\n",
        "\n",
        "def train(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    for X, y in loader:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_size = y.size(0)\n",
        "        running_loss += loss.item() * batch_size\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += batch_size\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "eAE9m1YM496G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Testing Function\n",
        "# -----------------------------\n",
        "\n",
        "def test(model, loader, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in loader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "            batch_size = y.size(0)\n",
        "            running_loss += loss.item() * batch_size\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += batch_size\n",
        "\n",
        "    avg_loss = running_loss / total\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "vcOhLBsY5BJt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqDksx0t4b-2",
        "outputId": "01b5c0ff-64aa-40f3-952c-2754679253d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/20 | Train Loss: 1.6083 | Train Acc: 41.10% | Test Loss: 1.2611 | Test Acc: 55.28%\n",
            "Epoch: 2/20 | Train Loss: 1.1597 | Train Acc: 58.36% | Test Loss: 0.9461 | Test Acc: 66.50%\n",
            "Epoch: 3/20 | Train Loss: 0.9239 | Train Acc: 67.60% | Test Loss: 0.8576 | Test Acc: 70.46%\n",
            "Epoch: 4/20 | Train Loss: 0.7893 | Train Acc: 72.32% | Test Loss: 0.6966 | Test Acc: 75.33%\n",
            "Epoch: 5/20 | Train Loss: 0.7059 | Train Acc: 75.70% | Test Loss: 0.6901 | Test Acc: 76.13%\n",
            "Epoch: 6/20 | Train Loss: 0.6427 | Train Acc: 77.56% | Test Loss: 0.5958 | Test Acc: 79.71%\n",
            "Epoch: 7/20 | Train Loss: 0.6004 | Train Acc: 79.21% | Test Loss: 0.5712 | Test Acc: 80.23%\n",
            "Epoch: 8/20 | Train Loss: 0.5602 | Train Acc: 80.58% | Test Loss: 0.5700 | Test Acc: 80.42%\n",
            "Epoch: 9/20 | Train Loss: 0.5218 | Train Acc: 81.99% | Test Loss: 0.5454 | Test Acc: 81.66%\n",
            "Epoch: 10/20 | Train Loss: 0.4975 | Train Acc: 82.86% | Test Loss: 0.5425 | Test Acc: 81.42%\n",
            "Epoch: 11/20 | Train Loss: 0.4644 | Train Acc: 84.06% | Test Loss: 0.4664 | Test Acc: 84.20%\n",
            "Epoch: 12/20 | Train Loss: 0.4473 | Train Acc: 84.32% | Test Loss: 0.4911 | Test Acc: 83.44%\n",
            "Epoch: 13/20 | Train Loss: 0.4237 | Train Acc: 85.33% | Test Loss: 0.4432 | Test Acc: 84.93%\n",
            "Epoch: 14/20 | Train Loss: 0.4061 | Train Acc: 86.07% | Test Loss: 0.4171 | Test Acc: 86.18%\n",
            "Epoch: 15/20 | Train Loss: 0.3883 | Train Acc: 86.48% | Test Loss: 0.4298 | Test Acc: 85.83%\n",
            "Epoch: 16/20 | Train Loss: 0.3690 | Train Acc: 87.31% | Test Loss: 0.4004 | Test Acc: 86.57%\n",
            "Epoch: 17/20 | Train Loss: 0.3577 | Train Acc: 87.64% | Test Loss: 0.4064 | Test Acc: 86.47%\n",
            "Epoch: 18/20 | Train Loss: 0.3431 | Train Acc: 88.24% | Test Loss: 0.4091 | Test Acc: 86.28%\n",
            "Epoch: 19/20 | Train Loss: 0.3325 | Train Acc: 88.54% | Test Loss: 0.4010 | Test Acc: 87.02%\n",
            "Epoch: 20/20 | Train Loss: 0.3189 | Train Acc: 88.92% | Test Loss: 0.3750 | Test Acc: 87.73%\n",
            "Training Time: 26.41 minutes!\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Training Loop\n",
        "# -----------------------------\n",
        "\n",
        "epochs = 20\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "    test_loss, test_acc = test(model, test_loader, criterion)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch: {epoch}/{epochs} | \"\n",
        "        f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc * 100:.2f}% | \"\n",
        "        f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc * 100:.2f}%\"\n",
        "    )\n",
        "\n",
        "print(f\"Training Time: {(time.time() - start_time) / 60:.2f} minutes!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HGU-6HcCHPa",
        "outputId": "12ee6aef-68c4-4a1a-e6a5-fdf7a966ef6f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/My Drive/Colab Notebooks/cifar10_model.pth\")\n",
        "print(\"✅ Model saved as cifar10_model.pth\")"
      ],
      "metadata": {
        "id": "QOMJaK_XCUuV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}